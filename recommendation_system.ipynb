{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github Projects\\Project\\Recommendation_System\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(url: str):\n",
    "\n",
    "    folder = \"Dataset\"\n",
    "    file_path = os.path.join(folder, \"data.csv\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Data already exists at : {file_path}\")\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            response = requests.get(url = url)\n",
    "            print(\"Successfully downloaded the dataset from url.\")\n",
    "\n",
    "            os.makedirs(folder, exist_ok = True)\n",
    "            print(\"Created a new Data folder to stiore the dataset.\")\n",
    "\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "            print(f\"Successfully downloaded the data in the location : {file_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded the dataset from url.\n",
      "Created a new Data folder to stiore the dataset.\n",
      "Successfully downloaded the data in the location : Dataset\\data.csv\n"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/611noorsaeed/All-Recommendations/raw/refs/heads/main/Articles.csv\"\n",
    "file_path = download_dataset(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(file_path, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article      Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  1/1/2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  1/2/2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  1/5/2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  1/6/2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  1/6/2015   \n",
       "\n",
       "                                             Heading  NewsType  \n",
       "0  sindh govt decides to cut public transport far...  business  \n",
       "1                    asia stocks up in new year trad  business  \n",
       "2           hong kong stocks open 0.66 percent lower  business  \n",
       "3             asian stocks sink euro near nine year   business  \n",
       "4                 us oil prices slip below 50 a barr  business  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"English\"))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    # Tokenize\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stopwords and apply stemming\n",
    "    preprocessed_text = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "\n",
    "    return \" \".join(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machin abil machin learn'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(\"Machine is the ability of machine how to learn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"cleaned_heading\"] = dataset[\"Heading\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
